import torchvision
import torch
aaaa=   [[[0.0116, 0.03857, 0.9454, 0.3402],
         [0.04021, 0.01515, 0.6301, 0.0718], 
         [0.06871, 0.06273, 0.8718, 0.3487], 
         [0.07753, 0.01358, 0.9282, 0.5879], 
         [0.04447, 0.07606, 0.7718, 0.2089], 
         [0.05661, 0.04690, 0.1704, 0.8201], 
         [0.01610, 0.04800, 0.0623, 0.5784], 
         [0.09735, 0.02063, 0.4258, 0.9247], 
         [0.09349, 0.03573, 0.9079, 0.9017], 
         [0.01685, 0.02096, 0.9077, 0.0664], 
         [0.07279, 0.01533, 0.4141, 0.8476]],
         
         [[0.0116, 0.03857, 0.9454, 0.3402],
         [0.04021, 0.01515, 0.6301, 0.0718], 
         [0.06871, 0.06273, 0.8718, 0.3487], 
         [0.07753, 0.01358, 0.9282, 0.5879], 
         [0.04447, 0.07606, 0.7718, 0.2089], 
         [0.05661, 0.04690, 0.1704, 0.8201], 
         [0.01610, 0.04800, 0.0623, 0.5784], 
         [0.09735, 0.02063, 0.4258, 0.9247], 
         [0.09349, 0.03573, 0.9079, 0.9017], 
         [0.01685, 0.02096, 0.9077, 0.0664], 
         [0.07279, 0.01533, 0.4141, 0.8476]],

         [[0.0116, 0.03857, 0.9454, 0.3402],
         [0.04021, 0.01515, 0.6301, 0.0718], 
         [0.06871, 0.06273, 0.8718, 0.3487], 
         [0.07753, 0.01358, 0.9282, 0.5879], 
         [0.04447, 0.07606, 0.7718, 0.2089], 
         [0.05661, 0.04690, 0.1704, 0.8201], 
         [0.01610, 0.04800, 0.0623, 0.5784], 
         [0.09735, 0.02063, 0.4258, 0.9247], 
         [0.09349, 0.03573, 0.9079, 0.9017], 
         [0.01685, 0.02096, 0.9077, 0.0664], 
         [0.07279, 0.01533, 0.4141, 0.8476]],

         [[0.0116, 0.03857, 0.9454, 0.3402],
         [0.04021, 0.01515, 0.6301, 0.0718], 
         [0.06871, 0.06273, 0.8718, 0.3487], 
         [0.07753, 0.01358, 0.9282, 0.5879], 
         [0.04447, 0.07606, 0.7718, 0.2089], 
         [0.05661, 0.04690, 0.1704, 0.8201], 
         [0.01610, 0.04800, 0.0623, 0.5784], 
         [0.09735, 0.02063, 0.4258, 0.9247], 
         [0.09349, 0.03573, 0.9079, 0.9017], 
         [0.01685, 0.02096, 0.9077, 0.0664], 
         [0.07279, 0.01533, 0.4141, 0.8476]]]





print("test: works")

model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
# For training
images, boxes = torch.rand(4, 3, 600, 1200), torch.tensor(aaaa)#torch.rand(4, 11, 4)
#print(boxes)

labels = torch.randint(1, 91, (4, 11))
images = list(image for image in images)
targets = []
for i in range(len(images)):
    d = {}
    d['boxes'] = boxes[i]
    d['labels'] = labels[i]
    targets.append(d)
output = model(images, targets)
# For inference
model.eval()
x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
predictions = model(x)
print(predictions.scores)
print(predictions['labels'])


# optionally, if you want to export the model to ONNX:
#torch.onnx.export(model, x, "faster_rcnn.onnx", opset_version = 11)
